---
title: "Assignment 5"
author: "Angie Bouche"
date: "November 27, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Load Tidyverse Etc
```{r}
library(tidyverse)
library(RColorBrewer)
library(kableExtra)
library(car)
read.csv("Doctoral_Salaries.csv")
read.csv("Faculty_Salaries.csv")
enrollment <- read.csv("Grad_enrollment.csv")
read.csv("phd.csv")

```

#Part 1
####Exploratory Scatterplot for Males and Females
```{r}
enrollment_line <- ggplot(enrollment, aes(x=Year))+
  geom_line(aes(y=Total_Males, colour = "Male Enrollment"))+
  geom_line(aes(y=Total_Females, colour = "Female Enrollment"))
   #Scatterplot of female enrollment

enrollment_line


```

####Linear Regression for Male and Female Enrollment
```{r}

menroll_model <- lm(Total_Males ~ Year, data = enrollment)
menroll_model
#results in equation y = - 17112153 + 9069x

fenroll_model <- lm(Total_Females ~ Year, data = enrollment)
fenroll_model
#results in equation y = - 58955502 + 30126x

```

#####Model Diagnostics, Fit and Significance
```{r}
plot(menroll_model)
par(mfrow = c(2,2))
plot(menroll_model)

#Q-Q plot appears normally distributed, but there seems to be peaks that don't match up with the red line on Residuals vs. Fitted graph.

summary(menroll_model)

#Multiple R-squared:  0.8545,	Adjusted R-squared:  0.8514 
#F-statistic:   276 on 1 and 47 DF,  p-value: < 2.2e-16
#Standard error  1087024 and 546

plot(fenroll_model)
par(mfrow = c(2,2))
plot(fenroll_model)

#Q-Q plot appears normally distributed, but there seems to be peaks that don't match up with the red line on Residuals vs. Fitted graph.

summary(fenroll_model)
#Multiple R-squared:  0.9827,	Adjusted R-squared:  0.9823 
#F-statistic:  2669 on 1 and 47 DF,  p-value: < 2.2e-16
#Standard error 1161000 and 583.2

```



#####Finalized Graph for Male and Female Enrollment
```{r}
enrollment_graph <- ggplot(enrollment, aes(x=Year))+
  geom_point(aes(y=Total_Males, color="green"))+ #add cl smooth
  geom_point(aes(y = Total_Females, color="red"))+
  geom_smooth(method = lm, se = TRUE, size = 0.5, color = "blue",(aes(y=Total_Males)))+
  geom_smooth(method = lm, se = TRUE, size = 0.5, color = "red",(aes(y=Total_Females)))+
  scale_colour_manual("", breaks = c("Total_Males", "Total_Females"), values = c("blue", "red")) +
  theme_classic()+
  scale_x_continuous(expand= c(0,0), limits= c(1967,2016))+
  labs(x= "Year", y = "Number of Students Enrolled")

enrollment_graph
  

```






#Part 4 - Multivariate linear regression

Exploring academic salaries for professors in U.S. colleges. Explore relationships between
variables in the ‘Faculty salary data (2008 - 2009 survey)’ dataset. Develop a model describing faculty salary based on data for faculty sex, rank, years in current position, field, and number of years since doctoral degree was earned. You should make decisions regarding which variables should remain in your final model. Describe the results qualitatively and quantitatively (i.e., don’t just report the statistical results of the model – make sure you describe interesting findings in text). You can also discuss any
concerns that you have with the model(s) you present, if any.

Dependent variable (y): faculty salary
Possible predictor variables: faculty sex, rank, years in current position, field, and number of years since doctoral degree was earned

Steps:
1) Explore data - find means of salary, make density plot of salary by diff predictor variables
2) Make initial model 
3) Test for colinearity
4) Refine model
3) Run diagnostic plots (to test Linearity, Independence, Homoscedasticity (residuals variance), Normality)
5) AIC to compare different models

##Make new dataframe 
```{r}
faculty_salary <- read_csv("Faculty_Salaries.csv")

#Reorder columns
faculty_salary <- faculty_salary[c("Salary", "Discipline", "Sex", "Faculty_Rank", "Years_Since_PhD", "Years_Faculty_Service")]
  
```

##Explore data
```{r}
#Salary means by Sex
sex_mean <- faculty_salary %>% 
  group_by(Sex) %>% 
  summarize(
    mean = mean(Salary)
  )

#Salary means by Discipline
discipline_mean <- faculty_salary %>% 
  group_by(Discipline) %>% 
  summarize(
    mean = mean(Salary)
  )

#Relationship between salary and faculty years of service
salary_service <- ggplot(faculty_salary, aes(x = Years_Faculty_Service, y = Salary)) +
  geom_point(aes(color = Sex, pch = Discipline))+
facet_wrap(~Discipline)

salary_service

#Relationship between salary and faculty rank, by sex and discipline
salary_yrs <- ggplot(faculty_salary, aes(x = Faculty_Rank, y = Salary)) +
  geom_point(aes(color = Sex, pch = Discipline), alpha = 0.5) +
  facet_wrap(~Discipline)

salary_yrs

```

##Linear regression model - Saturated (all variables)
```{r}
salary_lm1 <- lm(Salary ~ Discipline + Sex + Faculty_Rank + Years_Since_PhD + Years_Faculty_Service, data = faculty_salary)
summary(salary_lm1)

```

Salary = 78862.8 + 14417.6(Discipline B) + 4783.5(Sex Male) - 12907.6(AsstProf) + 32158.4(Prof) + 535.1(Years_Since_PhD) - 489.5 (Years_Faculty_Service)

Reference levels: Discipline A (0), Female (0), AssocProf (0)

But... this says that as you increase years of service, your salary decreases -> Might indicate collinearity

##Test for collinearity
```{r}
salary_simple <- faculty_salary %>% 
  select(Salary, Years_Since_PhD, Years_Faculty_Service)

cor(salary_simple) #High correlation bw Years_Since_PhD and Years_Faculty_Service

#VIF
vif(salary_lm1)

```
High correlation bw Years_Since_PhD and Years_Faculty_Service: 0.91

VIF
Years_Since_PhD: 7.51
Years_Faculty_Service: 5.92

So maybe should remove Years_Since_PhD - this makes sense conceptually, since years since phd is very similar to years of faculty service

##Linear regression model - subsets
```{r}
#Model without Years_Since_PhD 
salary_lm2 <- lm(Salary ~ Discipline + Sex + Faculty_Rank + Years_Faculty_Service, data = faculty_salary)
summary(salary_lm2)

vif(salary_lm2)

#Model without Years_Faculty_Service 
salary_lm3 <- lm(Salary ~ Discipline + Sex + Faculty_Rank + Years_Since_PhD, data = faculty_salary)
summary(salary_lm3)

vif(salary_lm3)

#Model without Years_Since_PhD and Years_Faculty_Service
salary_lm4 <- lm(Salary ~ Discipline + Sex + Faculty_Rank, data = faculty_salary)
summary(salary_lm4)

vif(salary_lm4)

```

Model lm2 (Model without Years_Since_PhD):
Salary = 82912.1 + 13473.4(Discipline B) +  4771.3(Sex Male) - 14560.4(AsstProf) + 34599.2(Prof) - 88.8 (Years_Faculty_Service)

Model lm3 (Model without Years_Faculty_Service):
Salary = 80988.5 + 13937.5(Discipline B) +  4349.4(Sex Male) - 13104.2(AsstProf) + 32928.4(Prof) + 61.0 (Years_Since_PhD)

Model lm4:
Salary = 81947 + 13709(Discipline B) +  4492(Sex Male) - 13723(AsstProf) + 33680(Prof) 

##Interaction terms?
```{r}
salary_lm5 <- lm(Salary ~ Discipline + Sex + Faculty_Rank + Years_Faculty_Service + Discipline*Years_Faculty_Service, data = faculty_salary)

summary(salary_lm5)
vif(salary_lm5)

#Relationship between salary and Years_Faculty_Service, by discipline
service_model <- lm(Salary ~ Years_Faculty_Service + Discipline, data = faculty_salary)

service_graph1 <- ggplot(faculty_salary, aes(x = Years_Faculty_Service, y = Salary))+
geom_point(aes(color = Discipline))+
  facet_wrap(~Discipline)+
  geom_smooth(method = lm, se = TRUE, size = 0.5, color = "gray20")
service_graph1

service_graph2 <- ggplot(faculty_salary, aes(x = Years_Faculty_Service, y = Salary))+
geom_point()+
  geom_smooth(method = lm, se = TRUE, size = 0.5, color = "gray20")
service_graph2

service_graph3 <- ggplot(faculty_salary, aes(x = Years_Since_PhD, y = Salary))+
geom_point()+
  geom_smooth(method = lm, se = TRUE, size = 0.5, color = "gray20")
service_graph3
```

Sex*Years_Faculty_Service insignificant
Discipline*Years_Faculty_Service significant

Sex*Years_Since_PhD insignificant
Discipline*Years_Since_PhD insignificant

Model lm5 (Model with interaction term):
Salary = 86338.5 + 6255.7(Discipline B) + 5196.1(Sex Male) - 13899.7(AsstProf) + 34121.8(Prof) - 266.8(ears_Faculty_Service) + 406.3(DisciplineB*Years_Faculty_Service)

##Diagnostic plots
```{r}
plot(salary_lm2)
plot(salary_lm3)
plot(salary_lm4)
plot(salary_lm5)
```
Residuals: homoscedastic??
Normality: yes??

##Akaike Information Criterion
```{r}
sat_aic <- AIC(salary_lm1)
sat_aic #9093.8

lm2_aic <- AIC(salary_lm2)
lm2_aic #9096.8

lm3_aic <- AIC(salary_lm3)
lm3_aic #9097.2

lm4_aic <- AIC(salary_lm4)
lm4_aic #9095.5

lm5_aic <- AIC(salary_lm5)
lm5_aic #9093.6

#lm4 < lm3 < lm2
```


Questions to ask: 
1) Which variable to include - PhD years increases, service years decreases. PhD has a higher correlation so based on that would we exclude? But if you look at graph the linear regression is better for years since PhD

2) Correlation terms - one is 0.7 one is 0.5, what does this actually mean and why does the correlation term change depending on which model you choose 

3) Correlation vs interaction term????

4) Interaction terms 
  -Which model to test them with 
  -Look for significance and low vif?
  -Graph why inc for A and inc for B leads to decrease for coefficient? Does the interaction   term cancel this out?
  
5) Non-normality and heteroscedacity 
  
